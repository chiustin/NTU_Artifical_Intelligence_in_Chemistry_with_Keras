{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2009 00:10:00</td>\n",
       "      <td>996.52</td>\n",
       "      <td>-8.02</td>\n",
       "      <td>265.40</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>93.3</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1307.75</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.75</td>\n",
       "      <td>152.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2009 00:20:00</td>\n",
       "      <td>996.57</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>265.01</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>93.4</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1309.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.50</td>\n",
       "      <td>136.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2009 00:30:00</td>\n",
       "      <td>996.53</td>\n",
       "      <td>-8.51</td>\n",
       "      <td>264.91</td>\n",
       "      <td>-9.31</td>\n",
       "      <td>93.9</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1310.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.63</td>\n",
       "      <td>171.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2009 00:40:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.31</td>\n",
       "      <td>265.12</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>94.2</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1309.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2009 00:50:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.27</td>\n",
       "      <td>265.15</td>\n",
       "      <td>-9.04</td>\n",
       "      <td>94.1</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1309.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>214.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Time  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
       "0  01.01.2009 00:10:00    996.52     -8.02    265.40        -8.90    93.3   \n",
       "1  01.01.2009 00:20:00    996.57     -8.41    265.01        -9.28    93.4   \n",
       "2  01.01.2009 00:30:00    996.53     -8.51    264.91        -9.31    93.9   \n",
       "3  01.01.2009 00:40:00    996.51     -8.31    265.12        -9.07    94.2   \n",
       "4  01.01.2009 00:50:00    996.51     -8.27    265.15        -9.04    94.1   \n",
       "\n",
       "   VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  \\\n",
       "0          3.33          3.11          0.22       1.94             3.12   \n",
       "1          3.23          3.02          0.21       1.89             3.03   \n",
       "2          3.21          3.01          0.20       1.88             3.02   \n",
       "3          3.26          3.07          0.19       1.92             3.08   \n",
       "4          3.27          3.08          0.19       1.92             3.09   \n",
       "\n",
       "   rho (g/m**3)  wv (m/s)  max. wv (m/s)  wd (deg)  \n",
       "0       1307.75      1.03           1.75     152.3  \n",
       "1       1309.80      0.72           1.50     136.1  \n",
       "2       1310.24      0.19           0.63     171.6  \n",
       "3       1309.19      0.34           0.50     198.0  \n",
       "4       1309.00      0.32           0.63     214.3  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('temperature.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.900080</td>\n",
       "      <td>-1.931243</td>\n",
       "      <td>-1.982008</td>\n",
       "      <td>-1.862774</td>\n",
       "      <td>1.073091</td>\n",
       "      <td>-1.307358</td>\n",
       "      <td>-1.473784</td>\n",
       "      <td>-0.798768</td>\n",
       "      <td>-1.476283</td>\n",
       "      <td>-1.478172</td>\n",
       "      <td>2.123687</td>\n",
       "      <td>-0.727723</td>\n",
       "      <td>-0.779684</td>\n",
       "      <td>-0.277693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.897721</td>\n",
       "      <td>-1.886062</td>\n",
       "      <td>-1.936218</td>\n",
       "      <td>-1.779038</td>\n",
       "      <td>1.162756</td>\n",
       "      <td>-1.293054</td>\n",
       "      <td>-1.438047</td>\n",
       "      <td>-0.807030</td>\n",
       "      <td>-1.438763</td>\n",
       "      <td>-1.442890</td>\n",
       "      <td>2.074970</td>\n",
       "      <td>-1.281252</td>\n",
       "      <td>-1.260773</td>\n",
       "      <td>-0.114206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.913050</td>\n",
       "      <td>-2.024996</td>\n",
       "      <td>-2.074707</td>\n",
       "      <td>-1.974423</td>\n",
       "      <td>1.085046</td>\n",
       "      <td>-1.334667</td>\n",
       "      <td>-1.519050</td>\n",
       "      <td>-0.802899</td>\n",
       "      <td>-1.521308</td>\n",
       "      <td>-1.522864</td>\n",
       "      <td>2.226299</td>\n",
       "      <td>-1.294276</td>\n",
       "      <td>-1.316614</td>\n",
       "      <td>-0.208614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.941348</td>\n",
       "      <td>-2.023866</td>\n",
       "      <td>-2.075824</td>\n",
       "      <td>-1.973027</td>\n",
       "      <td>1.085046</td>\n",
       "      <td>-1.333367</td>\n",
       "      <td>-1.519050</td>\n",
       "      <td>-0.802899</td>\n",
       "      <td>-1.517556</td>\n",
       "      <td>-1.522864</td>\n",
       "      <td>2.232418</td>\n",
       "      <td>-1.352885</td>\n",
       "      <td>-1.424000</td>\n",
       "      <td>-0.542494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.962572</td>\n",
       "      <td>-2.067919</td>\n",
       "      <td>-2.121614</td>\n",
       "      <td>-2.051181</td>\n",
       "      <td>1.007336</td>\n",
       "      <td>-1.346371</td>\n",
       "      <td>-1.550021</td>\n",
       "      <td>-0.794637</td>\n",
       "      <td>-1.551324</td>\n",
       "      <td>-1.553442</td>\n",
       "      <td>2.285372</td>\n",
       "      <td>-1.333349</td>\n",
       "      <td>-1.368159</td>\n",
       "      <td>0.316385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p (mbar)  T (degC)  Tpot (K)  Tdew (degC)    rh (%)  VPmax (mbar)  \\\n",
       "0   0.900080 -1.931243 -1.982008    -1.862774  1.073091     -1.307358   \n",
       "6   0.897721 -1.886062 -1.936218    -1.779038  1.162756     -1.293054   \n",
       "12  0.913050 -2.024996 -2.074707    -1.974423  1.085046     -1.334667   \n",
       "18  0.941348 -2.023866 -2.075824    -1.973027  1.085046     -1.333367   \n",
       "24  0.962572 -2.067919 -2.121614    -2.051181  1.007336     -1.346371   \n",
       "\n",
       "    VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  rho (g/m**3)  \\\n",
       "0      -1.473784     -0.798768  -1.476283        -1.478172      2.123687   \n",
       "6      -1.438047     -0.807030  -1.438763        -1.442890      2.074970   \n",
       "12     -1.519050     -0.802899  -1.521308        -1.522864      2.226299   \n",
       "18     -1.519050     -0.802899  -1.517556        -1.522864      2.232418   \n",
       "24     -1.550021     -0.794637  -1.551324        -1.553442      2.285372   \n",
       "\n",
       "    wv (m/s)  max. wv (m/s)  wd (deg)  \n",
       "0  -0.727723      -0.779684 -0.277693  \n",
       "6  -1.281252      -1.260773 -0.114206  \n",
       "12 -1.294276      -1.316614 -0.208614  \n",
       "18 -1.352885      -1.424000 -0.542494  \n",
       "24 -1.333349      -1.368159  0.316385  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:200000:6]\n",
    "df = df.drop(columns=['Date Time'])\n",
    "\n",
    "mean = df.mean()\n",
    "std = df.std()\n",
    "df = (df-mean)/std\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33332, 1, 14) (33332, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pastDay=1\n",
    "futureDay=1\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(df.shape[0]-futureDay-pastDay):\n",
    "    X.append(np.array(df.iloc[i:i+pastDay]))\n",
    "    y.append(np.array(df.iloc[i+pastDay:i+pastDay+futureDay][\"T (degC)\"]))\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29998, 1, 14) (3334, 1, 14) (29998, 1) (3334, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "config.gpu_options.allow_growth =True\n",
    "\n",
    "#set_session(tf.compat.v1.Session(config=config)) \n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10)                1000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,011\n",
      "Trainable params: 1,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, TimeDistributed\n",
    "from keras.callbacks import EarlyStopping\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26998 samples, validate on 3000 samples\n",
      "Epoch 1/1000\n",
      "26998/26998 [==============================] - 1s 46us/step - loss: 0.4213 - val_loss: 0.0773\n",
      "Epoch 2/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0480 - val_loss: 0.0388\n",
      "Epoch 3/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0274 - val_loss: 0.0232\n",
      "Epoch 4/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0191 - val_loss: 0.0182\n",
      "Epoch 5/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 6/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0153 - val_loss: 0.0154\n",
      "Epoch 7/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0146 - val_loss: 0.0148\n",
      "Epoch 8/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 9/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 10/1000\n",
      "26998/26998 [==============================] - 1s 31us/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 11/1000\n",
      "26998/26998 [==============================] - 1s 30us/step - loss: 0.0135 - val_loss: 0.0138\n",
      "Epoch 12/1000\n",
      "26998/26998 [==============================] - 1s 33us/step - loss: 0.0134 - val_loss: 0.0136\n",
      "Epoch 13/1000\n",
      "26998/26998 [==============================] - 1s 30us/step - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 14/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 15/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 16/1000\n",
      "26998/26998 [==============================] - 1s 33us/step - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 17/1000\n",
      "26998/26998 [==============================] - 1s 30us/step - loss: 0.0130 - val_loss: 0.0133\n",
      "Epoch 18/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0129 - val_loss: 0.0132\n",
      "Epoch 19/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0129 - val_loss: 0.0130\n",
      "Epoch 20/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0128 - val_loss: 0.0129\n",
      "Epoch 21/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 22/1000\n",
      "26998/26998 [==============================] - 1s 31us/step - loss: 0.0126 - val_loss: 0.0130\n",
      "Epoch 23/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 24/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0125 - val_loss: 0.0128\n",
      "Epoch 25/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 26/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 27/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 28/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 29/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 30/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 31/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0123 - val_loss: 0.0125\n",
      "Epoch 32/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 33/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 34/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 35/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 36/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 37/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 38/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 39/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0121 - val_loss: 0.0124\n",
      "Epoch 40/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 41/1000\n",
      "26998/26998 [==============================] - 1s 30us/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 42/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 43/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 44/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 45/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 46/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 47/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 48/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 49/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 50/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 51/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 52/1000\n",
      "26998/26998 [==============================] - 1s 30us/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 53/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 54/1000\n",
      "26998/26998 [==============================] - 1s 26us/step - loss: 0.0120 - val_loss: 0.0123\n",
      "Epoch 55/1000\n",
      "26998/26998 [==============================] - 1s 26us/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 56/1000\n",
      "26998/26998 [==============================] - 1s 26us/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 57/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 58/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 59/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 60/1000\n",
      "26998/26998 [==============================] - 1s 26us/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 61/1000\n",
      "26998/26998 [==============================] - 1s 26us/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 62/1000\n",
      "26998/26998 [==============================] - 1s 26us/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 63/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 64/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 65/1000\n",
      "26998/26998 [==============================] - 1s 32us/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 66/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 67/1000\n",
      "26998/26998 [==============================] - 1s 26us/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 68/1000\n",
      "26998/26998 [==============================] - 1s 26us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 69/1000\n",
      "26998/26998 [==============================] - 1s 26us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 70/1000\n",
      "26998/26998 [==============================] - 1s 34us/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 71/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 72/1000\n",
      "26998/26998 [==============================] - 1s 30us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 73/1000\n",
      "26998/26998 [==============================] - 1s 37us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 74/1000\n",
      "26998/26998 [==============================] - 1s 32us/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 75/1000\n",
      "26998/26998 [==============================] - 1s 31us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26998/26998 [==============================] - 1s 31us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 77/1000\n",
      "26998/26998 [==============================] - 1s 30us/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 78/1000\n",
      "26998/26998 [==============================] - 1s 32us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 79/1000\n",
      "26998/26998 [==============================] - 1s 31us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 80/1000\n",
      "26998/26998 [==============================] - 1s 31us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 81/1000\n",
      "26998/26998 [==============================] - 1s 34us/step - loss: 0.0119 - val_loss: 0.0122\n",
      "Epoch 82/1000\n",
      "26998/26998 [==============================] - 1s 32us/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 83/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 84/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 85/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 86/1000\n",
      "26998/26998 [==============================] - 1s 26us/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 87/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 88/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 89/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 90/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 91/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 92/1000\n",
      "26998/26998 [==============================] - 1s 26us/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 93/1000\n",
      "26998/26998 [==============================] - 1s 30us/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 94/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 95/1000\n",
      "26998/26998 [==============================] - 1s 29us/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 96/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 97/1000\n",
      "26998/26998 [==============================] - 1s 30us/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 98/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 99/1000\n",
      "26998/26998 [==============================] - 1s 30us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 100/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 101/1000\n",
      "26998/26998 [==============================] - 1s 28us/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 102/1000\n",
      "26998/26998 [==============================] - 1s 27us/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 00102: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=128, validation_split=0.1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3334/3334 [==============================] - 0s 48us/step\n",
      "0.011873513572175004\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'b', color='k', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', color='b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
